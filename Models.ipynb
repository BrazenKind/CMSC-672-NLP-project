{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3336adfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\tf3\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import regex as re\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import pandas as pd\n",
    "from Preprocessing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8235faa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class models:\n",
    "    \n",
    "    def __init__(self, train_x, train_y, dev_x = None, dev_y = None, test_x = None, test_y = None):\n",
    "        self.train_x = train_x\n",
    "        self.train_y = train_y\n",
    "        \n",
    "        self.dev_x = dev_x\n",
    "        self.dev_y = dev_y\n",
    "           \n",
    "        self.test_x = test_x\n",
    "        self.test_y = test_y\n",
    "        \n",
    "        self.Word2Vec = None\n",
    "        self.MaxEnt = None\n",
    "        \n",
    "        \n",
    "    def set_train_data(self, train_x, train_y):\n",
    "        \n",
    "        self.train_x = train_x\n",
    "        self.train_y = train_y\n",
    "        \n",
    "    def set_test_data(self, test_x, test_y):\n",
    "        \n",
    "        self.test_x = test_x\n",
    "        self.test_y = test_y\n",
    "        \n",
    "    def set_dev_data(self, dev_x, dev_y):\n",
    "        \n",
    "        self.dev_x = dev_x\n",
    "        self.dev_y = dev_y\n",
    "        \n",
    "        \n",
    "    def train_Word2Vec(self):\n",
    "        tagged_docs = [TaggedDocument(words = x, tags = str(y)) for x in self.train_x for y in self.train_y]\n",
    "        \n",
    "        x_merged = []\n",
    "        \n",
    "        for lst in self.train_x:\n",
    "            x_merged.extend(lst)\n",
    "        \n",
    "        x_dict = {x: x_merged.count(x) for x in set(x_merged)}\n",
    "        model_dm = Doc2Vec(dm = 1, vector_size = 300, epochs = 50)\n",
    "        model_dm.build_vocab_from_freq(x_dict)\n",
    "        model_dm.train(tagged_docs, total_examples=len(tagged_docs), epochs=model_dm.epochs)\n",
    "        \n",
    "        self.Word2Vec = model_dm\n",
    "        \n",
    "    \n",
    "    def train_MaxEnt(self):\n",
    "        \n",
    "        assert self.Word2Vec is not None, \"ERROR: Word2Vec model not initialized yet! Call models.Word2Vec() to initialize.\"\n",
    "        \n",
    "        train_x_vectorized = [self.Word2Vec.infer_vector(x) for x in train_x]\n",
    "        \n",
    "        logreg = LogisticRegression(max_iter = 1000, C=1e5)\n",
    "        logreg.fit(train_x_vectorized, train_y)\n",
    "        \n",
    "        self.MaxEnt = logreg\n",
    "        \n",
    "    def test\n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "10b040cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_vectorized = [model_dm.infer_vector(x) for x in train_x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1ab12adc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100000.0, max_iter=1000)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(max_iter = 1000, C=1e5)\n",
    "logreg.fit(train_x_vectorized, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389426ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f76b43b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "1\n",
      "[[4.08588891e-04 9.99591411e-01]]   0\n",
      "[-7.80280106e+00 -4.08672386e-04]\n",
      "-7.8028\n",
      "-0.00041\n",
      "0.00041\n",
      "0.99959\n",
      "False\n",
      "______\n",
      "[0]\n",
      "0\n",
      "[[0.66317791 0.33682209]]   0\n",
      "[-0.41071199 -1.08820041]\n",
      "-0.41071\n",
      "-1.0882\n",
      "0.66318\n",
      "0.33682\n",
      "False\n",
      "______\n",
      "[0]\n",
      "0\n",
      "[[1.00000000e+00 1.89134676e-12]]   0\n",
      "[-1.89137594e-12 -2.69937320e+01]\n",
      "-0.0\n",
      "-26.99373\n",
      "1.0\n",
      "0.0\n",
      "True\n",
      "______\n",
      "[0]\n",
      "0\n",
      "[[1.00000000e+00 2.12948654e-12]]   0\n",
      "[-2.12951878e-12 -2.68751402e+01]\n",
      "-0.0\n",
      "-26.87514\n",
      "1.0\n",
      "0.0\n",
      "True\n",
      "______\n",
      "[0]\n",
      "0\n",
      "[[1.00000000e+00 9.01047319e-11]]   0\n",
      "[-9.01047015e-11 -2.31300484e+01]\n",
      "-0.0\n",
      "-23.13005\n",
      "1.0\n",
      "0.0\n",
      "True\n",
      "______\n",
      "[0]\n",
      "0\n",
      "[[0.99216911 0.00783089]]   0\n",
      "[-0.00786172 -4.84967867]\n",
      "-0.00786\n",
      "-4.84968\n",
      "0.99217\n",
      "0.00783\n",
      "False\n",
      "______\n",
      "[0]\n",
      "0\n",
      "[[1.00000000e+00 2.05544826e-23]]   0\n",
      "[  0.         -52.23896319]\n",
      "0.0\n",
      "-52.23896\n",
      "1.0\n",
      "0.0\n",
      "True\n",
      "______\n",
      "[1]\n",
      "1\n",
      "[[8.20550849e-04 9.99179449e-01]]   0\n",
      "[-7.10553468e+00 -8.20887685e-04]\n",
      "-7.10553\n",
      "-0.00082\n",
      "0.00082\n",
      "0.99918\n",
      "False\n",
      "______\n",
      "[0]\n",
      "0\n",
      "[[9.99928373e-01 7.16268789e-05]]   0\n",
      "[-7.16294443e-05 -9.54404015e+00]\n",
      "-7e-05\n",
      "-9.54404\n",
      "0.99993\n",
      "7e-05\n",
      "False\n",
      "______\n",
      "[0]\n",
      "0\n",
      "[[9.99999959e-01 4.09384711e-08]]   0\n",
      "[-4.09384720e-08 -1.70111956e+01]\n",
      "-0.0\n",
      "-17.0112\n",
      "1.0\n",
      "0.0\n",
      "True\n",
      "______\n",
      "[1]\n",
      "1\n",
      "[[0.01806634 0.98193366]]   0\n",
      "[-4.01370462 -0.01823153]\n",
      "-4.0137\n",
      "-0.01823\n",
      "0.01807\n",
      "0.98193\n",
      "False\n",
      "______\n",
      "[0]\n",
      "0\n",
      "[[0.99801192 0.00198808]]   0\n",
      "[-1.99006122e-03 -6.22058474e+00]\n",
      "-0.00199\n",
      "-6.22058\n",
      "0.99801\n",
      "0.00199\n",
      "False\n",
      "______\n",
      "[0]\n",
      "0\n",
      "[[1.00000000e+00 6.00581985e-11]]   0\n",
      "[-6.00581807e-11 -2.35357070e+01]\n",
      "-0.0\n",
      "-23.53571\n",
      "1.0\n",
      "0.0\n",
      "True\n",
      "______\n",
      "[0]\n",
      "0\n",
      "[[9.99993370e-01 6.63001927e-06]]   0\n",
      "[-6.63004125e-06 -1.19239028e+01]\n",
      "-1e-05\n",
      "-11.9239\n",
      "0.99999\n",
      "1e-05\n",
      "True\n",
      "______\n",
      "[0]\n",
      "0\n",
      "[[9.99998141e-01 1.85940571e-06]]   0\n",
      "[-1.85940744e-06 -1.31952536e+01]\n",
      "-0.0\n",
      "-13.19525\n",
      "1.0\n",
      "0.0\n",
      "True\n",
      "______\n",
      "[0]\n",
      "0\n",
      "[[1.00000000e+00 4.89544283e-11]]   0\n",
      "[-4.89543961e-11 -2.37401313e+01]\n",
      "-0.0\n",
      "-23.74013\n",
      "1.0\n",
      "0.0\n",
      "True\n",
      "______\n",
      "[0]\n",
      "0\n",
      "[[1.00000000e+00 4.18894062e-11]]   0\n",
      "[-4.18893809e-11 -2.38959882e+01]\n",
      "-0.0\n",
      "-23.89599\n",
      "1.0\n",
      "0.0\n",
      "True\n",
      "______\n",
      "[0]\n",
      "0\n",
      "[[9.99858477e-01 1.41523324e-04]]   0\n",
      "[-1.41533340e-04 -8.86304602e+00]\n",
      "-0.00014\n",
      "-8.86305\n",
      "0.99986\n",
      "0.00014\n",
      "False\n",
      "______\n",
      "[1]\n",
      "1\n",
      "[[1.15913611e-07 9.99999884e-01]]   1\n",
      "[-1.59704207e+01 -1.15913617e-07]\n",
      "-15.97042\n",
      "-0.0\n",
      "0.0\n",
      "1.0\n",
      "False\n",
      "______\n",
      "[1]\n",
      "1\n",
      "[[2.25455540e-08 9.99999977e-01]]   1\n",
      "[-1.76077280e+01 -2.25455542e-08]\n",
      "-17.60773\n",
      "-0.0\n",
      "0.0\n",
      "1.0\n",
      "False\n",
      "______\n",
      "[1]\n",
      "1\n",
      "[[2.94998426e-09 9.99999997e-01]]   1\n",
      "[-1.96414660e+01 -2.94998426e-09]\n",
      "-19.64147\n",
      "-0.0\n",
      "0.0\n",
      "1.0\n",
      "False\n",
      "______\n",
      "[1]\n",
      "1\n",
      "[[3.47853746e-10 1.00000000e+00]]   1\n",
      "[-2.17792390e+01 -3.47853746e-10]\n",
      "-21.77924\n",
      "-0.0\n",
      "0.0\n",
      "1.0\n",
      "False\n",
      "______\n",
      "[1]\n",
      "1\n",
      "[[1.84287918e-10 1.00000000e+00]]   1\n",
      "[-2.24145218e+01 -1.84287918e-10]\n",
      "-22.41452\n",
      "-0.0\n",
      "0.0\n",
      "1.0\n",
      "False\n",
      "______\n",
      "[1]\n",
      "1\n",
      "[[7.64017790e-08 9.99999924e-01]]   1\n",
      "[-1.63872599e+01 -7.64017819e-08]\n",
      "-16.38726\n",
      "-0.0\n",
      "0.0\n",
      "1.0\n",
      "False\n",
      "______\n",
      "[1]\n",
      "1\n",
      "[[0.00584145 0.99415855]]   1\n",
      "[-5.14277594 -0.00585858]\n",
      "-5.14278\n",
      "-0.00586\n",
      "0.00584\n",
      "0.99416\n",
      "False\n",
      "______\n",
      "[1]\n",
      "1\n",
      "[[0.33209594 0.66790406]]   1\n",
      "[-1.10233137 -0.40361074]\n",
      "-1.10233\n",
      "-0.40361\n",
      "0.3321\n",
      "0.6679\n",
      "False\n",
      "______\n",
      "[1]\n",
      "1\n",
      "[[7.15892154e-08 9.99999928e-01]]   1\n",
      "[-1.64523214e+01 -7.15892180e-08]\n",
      "-16.45232\n",
      "-0.0\n",
      "0.0\n",
      "1.0\n",
      "False\n",
      "______\n",
      "[1]\n",
      "1\n",
      "[[1.04609325e-06 9.99998954e-01]]   1\n",
      "[-1.3770448e+01 -1.0460938e-06]\n",
      "-13.77045\n",
      "-0.0\n",
      "0.0\n",
      "1.0\n",
      "False\n",
      "______\n",
      "[1]\n",
      "1\n",
      "[[0. 1.]]   1\n",
      "[-inf   0.]\n",
      "-inf\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "False\n",
      "______\n",
      "[1]\n",
      "1\n",
      "[[0. 1.]]   1\n",
      "[-inf   0.]\n",
      "-inf\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "False\n",
      "______\n",
      "[1]\n",
      "1\n",
      "[[2.22044605e-16 1.00000000e+00]]   1\n",
      "[-3.60436534e+01 -2.22044605e-16]\n",
      "-36.04365\n",
      "-0.0\n",
      "0.0\n",
      "1.0\n",
      "False\n",
      "______\n",
      "[1]\n",
      "1\n",
      "[[0.2694544 0.7305456]]   1\n",
      "[-1.31135612 -0.31396362]\n",
      "-1.31136\n",
      "-0.31396\n",
      "0.26945\n",
      "0.73055\n",
      "False\n",
      "______\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\tf3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1499: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(self.predict_proba(X))\n",
      "C:\\Users\\user\\anaconda3\\envs\\tf3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1499: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(self.predict_proba(X))\n"
     ]
    }
   ],
   "source": [
    "for x in range(0, len(test_x)):\n",
    "    #print(logreg.predict_proba(model_dm.infer_vector(x).reshape(1, -1)))\n",
    "    x_vec = model_dm.infer_vector(test_x[x]).reshape(1, -1)\n",
    "    print(logreg.predict(x_vec))\n",
    "    predict = logreg.predict_proba(x_vec)\n",
    "    print(np.argmax(predict))\n",
    "    actual = test_y[x]\n",
    "                             \n",
    "    print(predict, ' ', actual)\n",
    "    log_predict = logreg.predict_log_proba(x_vec)[0]\n",
    "    print(log_predict)\n",
    "    for value in log_predict:\n",
    "        print(np.around(value, decimals = 5))\n",
    "    \n",
    "    print(np.around(predict[0][0], decimals = 5))\n",
    "    print(np.around(predict[0][1], decimals = 5))\n",
    "    \n",
    "    print(predict[0][1] < 0.00001)\n",
    "    print('______')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b33f692f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14.57798248])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg. decision_function(model_dm.infer_vector(['5G', 'causes', 'covid']).reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "90837d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(model_dm.infer_vector(['5G', 'causes', 'covid'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54301cb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf3",
   "language": "python",
   "name": "tf3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
